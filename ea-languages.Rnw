\documentclass[runningheads,a4paper]{llncs}

\usepackage{cite}
\usepackage{array}

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subfigure}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
opts_chunk$set(fig.width=8,fig.height=8,dev='png') 
library("ggplot2")
library("ggthemes")
library(RColorBrewer)
measures.bf <- read.csv('data/op-measures-bitflip.csv')
measures.xo <- read.csv('data/op-measures-xover.csv')
measures.mo <- read.csv('data/measures-maxones.csv')
op.ratios <- read.csv('data/ops-ratios.csv')
op.ranks <- read.csv('data/ops-rank.csv')
ratios <- read.csv('data/maxones-ratios.csv')
ranks <- read.csv('data/maxones-rank.csv')
@


\title{Ranking programming languages for evolutionary algorithm operations}

\author{Juan-Julián Merelo-Guervós\inst{1} \and Israel Blancas-Álvarez\inst{6},
    Pedro A. Castillo\inst{1} \and Gustavo Romero\inst{1} \and Pablo Garc{\'ia}-S{\'a}nchez\inst{2},
    Victor M. Rivas\inst{3},
    Mario García-Valdez \and Amaury Hernández-Águila\inst{4},
    Mario Román\inst{5}}
\institute{CITIC and Computer Architecture and Technology Department,  University of Granada (Spain), 
\email{(jmerelo,pacv,gustavo)@ugr.es}
\and
Department of Computer Engineering, University of C\'adiz (Spain), \email{pablo.garciasanchez@uca.es}
\and
Department of Computer Sciences, University of Jaén (Spain), \email{ vrivas@ujaen.es}
\and
Tijuana Institute of Technology (Mexico),\email{amherag,mario@tectijuana.edu.mx}
\and
University of Granada (Spain),\email{mromang08@correo.ugr.es}
\and
Real Time Innovations \email{iblancasa@gmail.com}
}

\maketitle

\keywords{Benchmarking, implementation of evolutionary algorithms,
  OneMax, genetic operators, programming languages, performance measurements.}

\begin{abstract}
In this paper we measure the speed of several popular and recent
programming languages performing the most usual operators in the
canonical evolutionary algorithm, mutation and crossover, as well as
an usual fitness function, OneMax.
These three operations are representative of the kind
of the ones performed in binary chromosomes.
Our main objectives are,
first, to create programs in programming languages that use the
fastest available implementation.
Second, to find out the differences in speeds for
the different languages.
Third, to find out whether the usual assumptions about the speed of languages really holds.
And, finally, to find if the assumed order of speed in languages used in evolutionary
algorithms holds true for all kinds of operations.
In order to do that, we use available implementations or perform our own, concluding that
the evolutionary algorithm scenario is more complex than usually
assumed and finding out some surprising {\em winners} and {\em losers} among the
languages tested.
\end{abstract}

\section{Introduction}

In the same spirit of the {\em No Free Lunch} theorem
\cite{Wolpert-1997-NFL} we could consider there is a {\em no fast
  lunch} \cite{2015arXiv151101088M}
hypothesis for the implementation of evolutionary optimization problems, in the
sense that, while there are particular languages that might be the
fastest for particular problem sizes and specially specific fitness functions
there is no single language that is the fastest for all problem domains
and design decisions.

That being the case, implementation decisions, and in many
occasions reviewer reports,
are based on common misconceptions such as thinking that a particular
language is the fastest or that some other language is too slow for even being
taken into consideration when implementing evolutionary algorithms. In
many cases, that decision is based on features of the language the
user knows, and the lack of information about new technologies and tools.

In fact, the current state of the art in application development
eschews monolithic applications for loosely coupled set of processing
components in the so-called {\em microservices architecture}, every one of them possibly written in a different
language and running on the cloud
\cite{wu2016least,zhang2008evolutionary,swann2015towards}.
In such an scenario, the possibility and even the likelihood of
multiple parts of an evolutionary algorithm being written in different
languages, every one of them suited to a particular component of the
evolutionary algorithm, becomes higher \cite{DBLP:journals/soco/Garcia-SanchezGCAG13}.
%Pablo: added our reference to SOEAs
Besides, as new languages become more familiar,
it is interesting to have an estimation of their
speed when running classical evolutionary algorithm
operations.
Furthermore, these asynchronous evolutionary algorithms
with polyglot components might insert a component of asynchrony
\cite{scott2015understanding,jj:2008:PPSN} that may have a positive
impact on the overall performance of the algorithm.

After initial tests on a smaller number of languages
\cite{DBLP:conf/evoW/MereloCBRGFRV16} and several data
structures, in this paper we test new languages, different data
structures, new implementations, including some made using
released evolutionary algorithm libraries, found and corrected some
bugs and also updated language versions in those cases where new, and faster,
ones have been released.

In order to make a fair comparison to the results we already had, we have re-used the same
operations: crossover, mutation and fitness computation (OneMax).
However, we have made an analysis that takes crossover and mutation in one hand and OneMax in
another, since our preliminary results showed that there was sometimes
a big difference between the speeds and their scale up found in one or
the other.

We have used just these functions instead of implementing a whole
evolutionary algorithm, first because it would have been impossible to
achieve this breadth of languages; and second, because these
operations, in fact, determine the total speed of an evolutionary
algorithm program; indeed, it might be the case that
\cite{DBLP:conf/iwann/MereloRACML11} an Evolutionary Algorithm (EA)
application will spend the most time running the fitness function and
others, such as ranking the population; however, these are well
covered by several general purpose benchmarks so they are not the focus of this paper.

A priori, results obtained here would generalize only to some
implementations of genetic
algorithms. However, in this paper we would like to present not only
the result itself, which is interesting, but also a methodology to
first assess new languages for implementing evolutionary algorithms
for the value or insights they might give to the algorithm mechanism.
Additionally, to make real-world measures and benchmark them to test their
speed and performance relative to other common languages instead of
choosing usual languages based only on past experience and common (maybe mis-) conceptions.

The rest of the paper is organized as follows: coming up next in
Section \ref{sec:soa}, we will present the state of the art of the
analysis of EA implementations. Next we will present in
Section \ref{sec:exp}
the tests we have used in this paper and its rationale along with the
languages we have chosen for carrying them out. Then, in Section
\ref{sec:res} we
will present the results obtained. Finally, we will explain the
conclusions reached after these experiments and present future lines of work.

\section{State of the art}
\label{sec:soa}

The point of benchmarking evolutionary algorithms is to discover which
languages are more suitable for speedily running evolutionary
experiments.

The
first published benchmarks of evolutionary algorithms \cite{jose1994genetic}
focused on implementation details using C and C++, while other papers
focused more on what kind of functions should be used to compare them
\cite{WHITLEY1996245}.

Despite the growing importance given to best practices in the software
creation process, there
are not many publications on the subject, until recently when Alba et al. examined
the performance of different data structures, all of them using the
Java language, in \cite{alba2007influence}. \cite{ae09}
described the implementation of an evolutionary algorithm in Perl,
also used in this paper, proving that, as a whole, Perl could run
evolutionary algorithms almost as fast as Java, but if we took
into consideration other factors like actual coding speed measured by
single lines of code, Perl was better. \cite{santana2011estimation}
focused on the estimation of distribution algorithms, evaluating several
metaheuristic packages having that particular option.
However, it was not focused on speed, but on availability and
languages used. Its survey did uncover the fact that most software
packages used C or C++.

Most papers, if not all, including this one, focus on single-threaded
procedural environments; for instance, a recent paper
\cite{nesmachnow2015empirical} centered on a single language, C++;
despite this being a object-oriented language, this feature was not
taken into account. In
these cases {\em classical} languages, optimized for the execution of
procedures and functions, not the dynamic creation of objects, have
a certain advantage. However, innovation in software engineering has not only spawned new
languages, but also new architectures like the Kappa architecture \cite{KappaArch},
microservices \cite{namiot2014micro} or
service-oriented frameworks
\cite{garcia2010distributed,DBLP:journals/soco/Garcia-SanchezGCAG13}
where we could envision that different parts of an evolutionary
algorithm might be written in different languages, but also in new,
domain specific,
languages better suited for certain tasks. The {\em no fast lunch} principle
enunciated above implies that different languages could be used for
distributed systems, with the fastest or most appropriate language
used for every part of it.

For instance, JavaScript is undoubtedly the best, if not the only,
language, that can be run natively in browsers; a volunteer
evolutionary computing system  such as the one described by Desell
\cite{desell2010analysis,desell2010validating} or Laredo
\cite{laredo2014designing} might leverage this fact to use mainly, or
exclusively, this particular language. A {\em polyglot} analysis of
languages for evolutionary algorithm such as the one done in this
paper will allow us to find out not only which languages are the
fastest in which environment, but also what is the actual difference
so that we can trade the speed difference for the convenience of using
a well-known tool ecosystem or a particular runtime environment.

All in all, existing literature focuses either on a single language
and different data structures or different, and mainly popular,
languages with a single data structure. In  previously published
research \cite{DBLP:conf/evoW/MereloCBRGFRV16} we focused on fewer
languages and mainly tried to measure their scaling behaviour across
different lengths, and we found that Java, C\# and C obtained the best
results. However, we did not attempt to rank languages or measure
relative speeds across all tests.  This is what we do in this paper,
extending the analysis of the previous paper with more languages and
different implementations. Next we will explain how the experiment was
set up and
the functions used in it.

\section{Experimental setup}
\label{sec:exp}

The main intention of this paper was to test new languages on these
genetic operators, so we have had to program from scratch these
functions, following in many cases instructions from experts so that
we managed to extract the maximum speed out of the data and control
structures for the particular language. As mentioned above, crossover,
mutation are the most widely used  operators for binary evolutionary
algorithms; OneMax is also a widely used fitness function and one
whose operations are representative or most binary fitness functions.
In general, they exercise only a small part of the capabilities of the
language,
involving mainly integer and memory-access performance through
loops. Their implementation of these operations is deceptively
simple, specially for OneMax, a problem frequently used in
programming job interviews but whose fastest implementation fully
depends on the language.

Any of these operations use loops. Most languages include
{\tt for} loops; many can also perform {\em map} implicit
loops where a function is applied to every component of a data structure,
reducing sequential or random access to arrays. Other, more complex
operations, such as {\em reduce}, which apply functions sequentially
to all members of an array accumulating over an initial value, are
sometimes available too.
When available, we have used them. This implies that
despite the simplicity of the benchmarking functions chosen, the
results have wider applicability, % change this if we include Griewank
                                  % - JJ
except
for floating point performance, which is not tested, mainly because it
is a major component of many fitness functions, not so much of the
evolutionary algorithm itself.

Data structures are the subject of these control structures; in this
case we are dealing with a single one, the {\em chromosome}, which is
widely accepted to be a list of zeros and ones. However, there are
many possible ways of interpreting the meaning of ``list'' and of
``zero'' and ``one''.

Let us pay attention first to the structure itself, the {\em
  list}. In general, it will need to be a data structure that uses
sequential access, a list or an array. However, for some fitness
functions such as the one we are using here, a simple set will
do. Mutation will be changing a single element in the set, crossover a
group of elements. On the other hand, the ``present''/''absent''
concept can be represented by three type of atomic scalar data: a
character (which is usually 1 or 0), an integer (1 or 0) or a Boolean
value (true or false). Depending o the data structure chosen, we might
have to choose a particular representation or not.
The data structures we are actually using in this
study can be divided into three different fields:\begin{itemize}
\item {\em Strings}: representing a set bit by ``1'' and unset by ``0'', it is
  a data structure present in all languages and simple to use in
  most. In general, strings are used for its legibility and also the
  memory efficiency of storing values contiguosly. However, it need
  not be the most efficient one when computing fitness.
\item {\em Vectors of Boolean values}, or Bit Vectors: not all languages have a
  specific primitive type for the Boolean false and true values; for
  those who have, sometimes they have specific implementations that
  make this data structure the most efficient. In some and when they
  Boolean values were not available, 1 or 0 were used. {\em Bitsets}
  are a special case, using bits packed
  into bytes for representing vector of bits, with 32 bits packed into a
  single 4 byte data structure and bigger number of bytes used as
  needed.
\item {\em Lists} are accessed only sequentially, although running
  loops over them might be more efficient that using random-access
  methods such as the ones above. {\em Sequences} are functional data
  structures that differ from Lists in their finite size and the set
  of operations they are optimized for.
\end{itemize}

Besides, many languages, including functional ones, differentiate
between Mutable and Constant or Immutable data structures, with different internal
representations assigned to every one of them, and extensive
optimizations used in Immutable or constant data structures. Immutable
data structures are mainly used in functional languages, but some
scripting languages like Ruby or Python use it for strings too. When
available, we have also tested this type of data structures.

In this paper we have run the benhmarks in more than 20 different
languages; additionally, another language,
Rust, has been tested for one of them, and Clojure using persistent vectors was
tested only for OneMax. This list includes 9 languages from the top 10 in
the TIOBE index \cite{tiobe16}, with Visual Basic the only one
missing, and 10 out of the top 20\footnote{Considering that Octave and
  Matlab actually use the same language. Besides, we have not measured
  proprietary implementations of languages such as that one}. We have
also added Perl6, which was in early releases in our previous
papers and has advanced its speed greatly in the last releases.
The list of languages and alternative
implementations is shown in Table \ref{tab:files}.

\begin{table*}[h!tb]
    \centering
    \begin{tabular}{l|c|l|l|l}
      \hline
      Language & Version & URL & Data structures & Type\\
      \hline %Pablo: replace ANONSERVER with git.io after acceptance!!!
      C & 4.8.2 & \url{http://git.io/v8T57} & String & Compiled \\
      C++ & 4.8.4 & \url{http://git.io/v8T57} & Bit Vector  & Compiled\\
      C\# & mono 4.2  & \url{https://git.io/vzHDI} & Bit Vector  & Compiled\\
      Clojure & 1.8.0 & \url{https://git.io/vzHDe} & Bit Vector &  Compiled \\
      Common Lisp & 0.13.7 & \url{https://git.io/vzHyR} & Simple Bit Vector &  Compiled\\
      Dart & 1.15.0 & \url{https://git.io/dEO} & List & Interpreted \\
      Go & go1.5.3 & \url{http://git.io/vBSYp} & Bit Vector & Compiled\\
      Haskell & ghc 7.10.3 & \url{https://git.io/vzHMw} & Mutable Vector & Compiled \\
      Java & 1.8.0\_66 & \url{http://git.io/v8TdR} & Bitset & Compiled\\
      JavaScript & node.js 5.0.0 & \url{http://git.io/vBSYd} & String & Interpreted\\
      JRuby & 9.0.5.0 (2.2.3) & \url{https://git.io/rEO} & Bit Vector & Interpreted \\
      Julia & 0.2.1 & \url{http://git.io/vBSOe} & Bit Vector & Interpreted \\
      Kotlin & 1.0.1 & \url{https://git.io/kEO} & Bit Vector &  Compiled \\
      Lua & 5.3.3 & \url{http://git.io/vBSY7} & String & Interpreted\\
      Octave & 3.8.1 & \url{http://git.io/v8T57} & BitVector & Interpreted \\
      Pascal & Free Pascal 2.6.2-8 & \url{https://git.io/fpeo} & Bit Vector & Compiled \\
      PHP & 5.5.9 & \url{http://git.io/v8k9g} & String & Interpreted\\ % vrivas, 5-nov-2015
      Perl & v5.24.0 & \url{http://git.io/bperl} & String & Interpreted \\
      Perl6 & 2016.09.1 & \url{http://git.io/bperl6} & String, Bit Vector & Interpreted \\
      Python & 2.7.3 & \url{http://git.io/vBSYb} & String & Interpreted\\
      Python 3 & 3.4.3 & \url{https://git.io/p3deap} & Bit Vector, List & Interpreted\\
      Ruby & 1.9.3p551 & \url{https://git.io/rEO} & Bit Vector & Interpreted \\
      Rust &  1.4.0  & \url{https://git.io/EOr} & Bit Vector  & Compiled \\
      Scala & 2.11.7 & \url{http://git.io/vBSYH} & String, Bit Vector & Compiled \\
      \hline
      \end{tabular}
      \vspace{5mm}
      \caption{Languages, versions, URLs, data structures and type of
        language used to carry out the
        benchmarks. No special flags were used for the interpreter or
        compiler. \label{tab:files}}
    \end{table*}
%

When available, available open source implementations of the operators
and OneMax were used.
In most cases, implementation took less than one hour and was
inspired by the initial implementation made in Perl or in Lua;
however, finetuning and improving from the last version published, as
well as the testing of several versions of the language to choose the
fastest, took longer. Adequate data and control
structures were used for running the application, which applies
mutation to a single generated chromosome, or pair of them, a hundred thousand
times. The length of the mutated string starts at 16 and is doubled
until reaching $2^{15}$, that is, 32768; in some cases we stopped at
$2^{14}$ if it took more than one hour; we also extended it in some
cases to $2^{16}$.

In most cases, and especially in the ones where no implementation was
readily available, we wrote small programs with very little overhead
that called the functions directly. Using classes,
function-call chains, and other artifacts, will add an overhead to the
benchmark and will need to be different for each language. However,
legibility or other constraints will make us use it anyway; this will
have an influence in performance, but the differences  will reflects
what would be available for anyone implementing an evolutionary
algorithm in a new language.

Every program uses native functions for measuring time, using system
calls to check the time before and after operations
were performed. These facilities used the maximum resolution
available, which in some cases, namely Pascal, was somewhat
inadequate. This was preferred to using external facilities since
loading times, which are not important when running long experiments,
will be different for compiled and interpreted languages; besides,
external time will be more influenced by things like the hard drive
state or other programs running.

In this paper, besides revising implementations of several functions
with respect to \cite{DBLP:conf/evoW/MereloCBRGFRV16}, we
have also added new languages and tested new versions of compilers and
interpreters. The focus of this paper is also different: while in the
previous papers our intention was to compute speeds, in this we aim to
prove that there is no single implementation that beats all others in
every aspect of an evolutonary algorithm.

\section{Results and analysis}
\label{sec:res}

%
\begin{figure}[h!tb]
  \centering
<<results-bf, cache=FALSE,echo=FALSE,fig.width=12,fig.height=8,fig.dpi=300, dev='png'>>=
colourCount = length(unique(measures.bf$languagerepresentation))
getPalette = colorRampPalette(brewer.pal(9, "Set1"))
ggplot(measures.bf,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point() +  ggtitle("Benchmarks: Bitflip")+scale_y_log10()+scale_x_log10()+scale_color_manual(name='Language',values=getPalette(colourCount))+theme( text = element_text(size=20),legend.position="bottom")+guides(colour = guide_legend(title.position = "bottom"))
@
\caption{Plot of the time needed to perform 100K mutations in strings with
lengths increasing by a factor of two from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale. Every language key includes the data structure used; it will be maintained in the rest of the paper.}
\label{fig:time}
\end{figure}
%
\begin{figure}[h!tb]
  \centering
<<results-xo, cache=FALSE,echo=FALSE,fig.width=12,fig.height=8,fig.dpi=300, dev='png'>>=
colourCount = length(unique(measures.bf$languagerepresentation))
getPalette = colorRampPalette(brewer.pal(9, "Set1"))
ggplot(measures.xo,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point() +  ggtitle("Benchmarks: Crossover")+scale_y_log10()+scale_x_log10()+scale_color_manual(name='Language',values=getPalette(colourCount))+theme( text = element_text(size=20),legend.position="bottom")+guides(colour = guide_legend(title.position = "bottom"))
@
\caption{Plot of the time needed to perform 100K crossovers in strings with
lengths increasing by a factor of two from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:time:xo}
\end{figure}
%
\begin{figure}[h!tb]
  \centering
<<results-mo, cache=FALSE,echo=FALSE,fig.width=12,fig.height=8,fig.dpi=300, dev='png'>>=
colourCount = length(unique(measures.mo$languagerepresentation))
ggplot(measures.mo,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point() +  ggtitle("Benchmarks: OneMax")+scale_y_log10()+scale_x_log10()+scale_color_manual(name='Language',values=getPalette(colourCount))+theme( text = element_text(size=20),legend.position="bottom")+guides(colour = guide_legend(title.position = "bottom"))
@
\caption{Plot of time needed to perform 100K OneMax evaluations in strings with
lengths increasing by a factor of two from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:time:mo}
\end{figure}
%

All the results have been made available, with a free license, in the repository that holds
this paper as well as some of the implementations, at
\url{https://git.io/bPPSN16}. 
The Linux system we have used for testing runs the {\tt
 3.13.0-34-generic \#60-Ubuntu SMP} kernel on an {\tt Intel(R) Core(TM)
  i7-4770 CPU @ 3.40GHz} CPU. Results for bitflip mutation, crossover and OneMax
are shown in Figures \ref{fig:time}, \ref{fig:time:xo} and
\ref{fig:time:mo}. The graphs for crossover and mutation mainly show how time needed to
perform varies more or less linearly with size; but in the case of
some languages, the fact that they do not change that way make them show a stronger
performance in the long run; for instance, Octave does not increase
too much the time with size, making it faster at bigger sizes. . The case of Java is really remarkable, in
fact. We will examine aggregated results next.


\begin{figure*}[h!tb]
  \centering
<<results-ops-ratios,message=FALSE, cache=FALSE,echo=FALSE,fig.width=18,fig.height=12,fig.dpi=300, dev='png'>>=
ggplot(op.ratios,aes(x=reorder(Language, -Ratio, FUN=median),Language,y=Ratio))+ geom_boxplot(notch=TRUE)+ theme( text = element_text(size=36),axis.text.x = element_text(angle = 90, hjust = 1))+scale_y_log10()+labs(x='Language',title='Scaled performance, Operators')
@
\caption{Boxplot of scaled performance in mutation and crossover compared to the baseline
 language, which has been chosen to be Julia. Please note
that $y$ has a logarithmic scale. The strings indicate the language
and the implementation; for instance, Python\_DEAP\_numpy is a python
implementation using the operators in the DEAP framework \cite{fortin2012deap} and {\tt
  numpy} implementation for vectors. }
\label{fig:ops:ratios}
\end{figure*}
%
\begin{figure*}[h!tb]
  \centering
<<results-ratios,message=FALSE, cache=FALSE,echo=FALSE,fig.width=18,fig.height=12,fig.dpi=300, dev='png'>>=
ggplot(ratios,aes(x=reorder(Language, -Ratio, FUN=median),Language,y=Ratio))+ geom_boxplot(notch=TRUE)+ theme( text = element_text(size=36),axis.text.x = element_text(angle = 90, hjust = 1))+scale_y_log10()+labs(x='Language',title='Scaled performance, OneMax')
@
\caption{Boxplot of scaled performance in the OneMax function compared to baseline Julia. Please note
that $y$ has a logarithmic scale. }
\label{fig:ratios}
\end{figure*}
%
To have a general idea of performance and be able to compare across
benchmarks and sizes, we have used the language Julia, whose
performance is more or less in the middle, as a baseline for comparison
and expressed all times as the ratio between the time needed for a
particular language and length and the time it takes the equivalent
program in Julia. Ratios higher than 1 mean that the particular
language+data
structure is faster than Julia, $<$1 the opposite. The
boxplot in Figure \ref{fig:ops:ratios} shows the average and standard
deviation for all available lengths for the genetic operators; Figure
\ref{fig:ratios} shows the same for OneMax.

First result we wanted to find out, orders of magnitude in speed, can
be checked by looking at the scale, which goes from faster and
approximately 100 times as fast as Julia, to approximately 20 times as
slow as Julia, that is, more than three orders of magnitude. In fact,
the fastest is 10 times as fast as the 10th fastest for genetic
operators, but almost a thousand times faster for OneMax. This also
implies that fitness calculation is more speed-critical than genetic
operators, but even so choosing a slow language might result in a
program that is 100 or even one thousand times slower than the
fastest. The second, is the comparison between languages, which,
besides the usual suspects Java and C\#, also show surprising entries:
Haskell is the fastest running OneMax, and Go can be faster than C\#;
Kotlin and Go are also faster than C, and C++ is not as fast as would
be expected.

Independenly of the raw speed diferences, let us have a look at all
possible chromosome lengths and let us compute the average ranks, that
is, the average position in which they fall for all possible tests and
lengths. The averaged ranking for genetic operators is shown in Figure
\ref{fig:ranks:ops} and for OneMax in \ref{fig:ranks} averages the position reached for all sizes and
functions, and subtracts it from the total number of languages
tested, so that bigger is better.
%
\begin{figure*}[h!tb]
  \centering
<<results-ranks-ops,message=FALSE, cache=FALSE,echo=FALSE,fig.width=18,fig.height=12,fig.dpi=300, dev='png'>>=
ggplot( op.ranks, aes(x=reorder(LanguageData,AvgRank), y=25-AvgRank))+ geom_bar(stat='identity',fill='orange',color='darkblue')+ theme_tufte() + theme( text = element_text(size=36),axis.text.x = element_text(angle = 90, hjust = 1))+labs(title='Average rank, Operators',x='Language+Data Structure',y='25-average rank')
@
\caption{Ranking averaged across all measures for genetic operators
  crossover and mutation, subtracted from the
  total number of measured languages, so bigger is better}
\label{fig:ranks:ops}
\end{figure*}
%
\begin{figure*}[h!tb]
  \centering
<<results-ranks,message=FALSE, cache=FALSE,echo=FALSE,fig.width=18,fig.height=12,fig.dpi=300, dev='png'>>=
ggplot( ranks, aes(x=reorder(LanguageData,AvgRank), y=27-AvgRank))+ geom_bar(stat='identity',fill='orange',color='darkblue')+ theme_tufte() + theme( text = element_text(size=36),axis.text.x = element_text(angle = 90, hjust = 1))+labs(title='Average rank, OneMax',x='Language+Data Structure',y='27-average rank')
@
\caption{Ranking averaged across all measures for OneMax, subtracted from the
  total number of measured languages, so bigger is better.}
\label{fig:ranks}
\end{figure*}
%

The first ranking for genetic operators shows C\# as the first,
on average, but also Go as the second and forth, depending on the data
structure, with PHP as 4th and C as fifth. Due to its slow performance
in the crossover operator, Java drops to 9th position, even if it
performs very well in the mutation operator. JRuby is the only
interpreted language to show a strong performance, on average, in the
top 10 area.

Except for C\#, the top 5 for the OneMax operator is completely
different, including Java as the first, Haskell and Clojure with two
different representations. JRuby, Node and Octave are representatives
of the interpreted languages crowd in the top 10.

In general, it is always compiled languages the ones that occupy the
first positions. However, interpreted languages such as node.js, Perl,
Lua and even PHP present a performance that, if not top, is at least
relatively competitive with other compiled languages such as Pascal or
C++. Thus, it is not always true that compiled languages are {\em
  always} faster than interpreted; but it can be said that the fastest
languages are, consistently, compiled languages.

However, it is quite clear that the performance is not consistent
across all operators for practically any language; Java is very fast
evaluating OneMax, but slower than others using genetic operators; the
case of Haskell is remarkable, because even being faster than Java on
average evaluating OneMax, it is slower than even Perl6, the new entry
in this paper, using genetic operators.

\section{Conclusions}

In this paper we have measured the performance of an extensive
collection of languages in simple and common evolutionary algorithm
operations: mutation, crossover and OneMax, with the objective of
finding out which languages are faster at these operations and what
are the actual differences across languages, operators and data
structures, the main objective being giving EA practitioner elements
%Pablo: two times mentioned the word "objective" in this paragraph. Maybe divide into two?
of decision to choose which language or languages to
use when implementing evolutionary algorithms.

%Rewrite conclusions
In a development environment where different parts of the application
might be performed using microservices \cite{swann2015towards}, it is interesting to know
%Pablo: added Jerry's reference
which particular language is the best for specific operations. Pool
based evolutionary algorithms \cite{merelo2012pool} favor
decomposition of concerns to different processing units following a
microservices approach; in this case, a unit performing fitness %Pablo: "a yunit", not "an iunit" :)
evaluation might be different from other performing mutation or
crossover. Modern cloud architectures also reduce ping and increase
throughput so it is economical and sensible to perform this operation
even if they are in different instances.

Bearing in mind this environment, we can conclude that functional
%Pablo: we are concluding here, but not a mention to the experiments in previous paragraphs. Maybe add "after a complete experimental section taking into account this and that, we can conclude..."
languages such as Haskell or Clojure are the fastest evaluating
fitness functions similar to OneMax; we could include here Royal Road,
%Pablo: we are mixing experimental results and future works in this phrase
HIFF and other similar functions; Java and C\# would be also strong
contenders among the more popular languages, and JRuby would be the
fastest among interpreted languages.
On the other hand, Go is the best language processing genetic operators
over binary strings, very close to the more popular languages Java and C\#;
as far as the interpreted languages is concerned, both PHP and Perl
obtain the best results.
Even if these results confirm that Java and C\# are very fast at
solving evolutionary algorithms, we have also proved that often
overlooked languages such as Go and Kotlin should also be considered
for implementing these monolithic applications.

That leads us to conclude that Java or C\# would be the fastest choice
in a canonical evolutionary algorithm, when solving problems similar to
the OneMax.
However, evaluating binary fitness functions using a distributed microservices
architecture would be better solved using Haskell or Clojure,
while Go and even Perl might be better suited for performing genetic
operators.
In any case, this study shows that it is always a good practice to
measure and compare the actual performance of the proposed implementation,
and consider the possibility of using different data
structures and even languages for our evolutionary algorithm
application.

Future lines of work will include actual measurements in distributed
applications to find the impact of the network on the final
performance. These measurements will have to be taken in the whole system,
so in advance a more extensive measurement of
other operators such as  tournament selection and other selection
methods will have to be performed. {\em A priori}, these are essentially CPU integer
operations and their behavior might be, in principle, very similar to
the one shown in these operations. Combining some compiled languages such as Go or
C with others characterized by its speed in some string operations,
like Perl or programming ease, like Python, might result in the best of both worlds:
performance and rapid prototyping. Creating a whole multi-language
framework along these lines is a challenge that might be interesting
to carry out in the future.

\section*{Acknowledgements}

 This paper is part of the open science effort at the university of
 Granada. It has been written using {\tt knitr}, and its source as well as
 the data used to create it can be downloaded from
 \href{https://github.com/JJ/2016-ea-languages-PPSN}{the GitHub
   repository} \url{https://github.com/geneura-papers/2016-ea-languages-PPSN/}.
 It has been supported in part by
 \href{http://geneura.wordpress.com}{GeNeura Team},
 projects TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitiveness),
 Conacyt Project PROINNOVA-220590.

\bibliographystyle{splncs}
\bibliography{geneura,languages,GA-general}

\end{document}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% hunspell-local-dictionary: "english"
%%% End:
